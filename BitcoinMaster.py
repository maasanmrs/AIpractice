# -*- coding: utf-8 -*-
"""BitcoinBot更新版.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uy0swl1KD3gtExAyuWHaI7AjnmESldUj

PDFを投げるとその文章を読み込み、その文章に関しての質問に答えてくれるチャットボット

PDFからテキストデータを読み込み
"""

!pip install -U langchain-community # Install the langchain community package

#必要なライブラリインポート
# Embedding用
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
# テキストファイルを読み込む
from langchain.document_loaders import TextLoader

!pip install langchain==0.0.125 openai==0.27.2 chromadb==0.3.14 pypdf==3.7.0 tiktoken==0.3.3 gradio==3.23

#必要なライブラリのインストール
!pip install langchain
!pip install -q -U google-generativeai

from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import OpenAI
from langchain.chains import VectorDBQA, RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import TextLoader, PyPDFLoader

import os
#Geminiに変更
#os.environ["OPENAI_API_KEY"] = "***"

#Google Driveへのアクセス許可
from google.colab import drive
drive.mount('/content/drive')

# 環境変数の準備
import google.generativeai as genai
from google.colab import userdata
GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')

genai.configure(api_key=GOOGLE_API_KEY)

loader = PyPDFLoader('/content/drive/MyDrive/19_28The Bitcoin Standard.pdf')
documents = loader.load()

import pandas as pd # Import the pandas library and give it the alias 'pd'

df = pd.DataFrame(documents)

df.head()

df.columns

df=df.drop(0,axis=1).drop(3,axis=1)
DF1=df

df.head()

"""## データの加工
apply関数を使用しdfをsourceとcontentsのみに変換
また、contentsの序盤60文字部分ほどの不要な部分を削除

"""

DF1[1]=df[1].apply(lambda x: x[1]['source'])
DF1[2]=df[2].apply(lambda x: x[1][65:])

DF1=DF1.rename(columns={1: 'source',2:'contents'})
DF1

"""データセット完成  

##embedding
以下indexごとにembeddingをする
"""

!pip install -q langchain

import pathlib
import textwrap

import google.generativeai as genai
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

from IPython.display import display
from IPython.display import Markdown


def to_markdown(text):
  text = text.replace('•', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

# Assuming 'texts' is your list of strings, convert them to Document objects
#documents = [Document(page_content=t) for t in texts]

#text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
#split_texts = text_splitter.split_documents(documents) # Pass the list of Document objects

# Used to securely store your API key
from google.colab import userdata

embeddings = genai.embed_content(
    model="models/embedding-001",
    content=[Document(page_content=text).page_content for text in DF1['contents']],  # Create Document objects and extract text for each element in DF1[0]
    task_type="retrieval_document",
    title="The Bitcoin Standard"
)

#データフレームに見やすく格納
DF1['Embeddings']=embeddings['embedding']
df=DF1
df

"""embedding終了

Chatbot用のUIの実装とChatbotに入力された質問をembedingして、類似した文章を探し、一番類似した文章を入力としてGeminiに回答を生成させる。フロントはサイトの流用


#参考にしたもの
https://ai.google.dev/gemini-api/tutorials/document_search?hl=ja

https://youtu.be/eCtHVmXcXMs?si=4uF4qrCmaZ2XKz_H
"""

import numpy as np

from langchain import PromptTemplate

import gradio as gr

def to_markdown(text):
  text = text.replace('•', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))


def add_text(history, text):
    history = history + [(text, None)]
    return history, ""

def bot(history):

    query = history[-1][0]
    #query = prompt.format(question=query)
    model = 'models/embedding-001'

    request = genai.embed_content(model=model,
                                  content=query,
                                  task_type="retrieval_query")

    def find_best_passage(query, dataframe):
        """
        Compute the distances between the query and each document in the dataframe
        using the dot product.
        """
        query_embedding = genai.embed_content(model=model,
                                        content=query,
                                        task_type="retrieval_query")
        dot_products = np.dot(np.stack(df['Embeddings']), query_embedding["embedding"])
        idx = np.argmax(dot_products)
        return dataframe.iloc[idx]['contents'] # Return text from index with max value

    passage = find_best_passage(query, df)
    passage


    def make_prompt(query, relevant_passage):
      escaped = relevant_passage#.replace("'", "").replace('"', "").replace("\n", " ")
      prompt = textwrap.dedent("""You are a helpful and informative bot that answers questions using text from the reference passage included below. \
                                 Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \
                                  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \
                                    strike a friendly and converstional tone. \
                                 If the passage is irrelevant to the answer, you may ignore it.
                                  QUESTION: '{query}'
                                    PASSAGE: '{relevant_passage}'

                                  ANSWER:
                                """).format(query=query, relevant_passage=escaped)

      return prompt

    prompt = make_prompt(query, passage)
    print(prompt)

    model = genai.GenerativeModel('gemini-1.5-pro-latest')
    answer = model.generate_content(prompt).text





    #source = qa._get_docs(query)[0]
    #source_sentence = source.page_content
    #answer_source = source_sentence +"\n"+"source:"+source.metadata["source"] + ", page:" + str(source.metadata["page"])
    history[-1][1] = answer # + "\n\n情報ソースは以下です：\n" + answer_source
    return history




with gr.Blocks() as demo:
    chatbot = gr.Chatbot([], elem_id="chatbot").style(height=400)

    with gr.Row():
        with gr.Column(scale=0.6):
            txt = gr.Textbox(
                show_label=False,
                placeholder="Enter text and press enter",
            ).style(container=False)

    txt.submit(add_text, [chatbot, txt], [chatbot, txt]).then(
        bot, chatbot, chatbot
    )

demo.launch(debug=True)